import os
import json
import cv2
import numpy as np
import pickle
import joblib
from datetime import datetime
from typing import Dict, Any, Tuple
import tempfile

from src.procesamiento.postprocesamiento import calcular_porcentaje_suelo

class ProcesamientoServiceV2:
    """
    Servicio actualizado para procesar im√°genes con modelo perfeccionado
    """
    
    def __init__(self, modelo_path: str = "modelo_perfeccionado.pkl"):
        self.modelo_path = modelo_path
        self.modelo = None
        self.scaler = None
        self.encoder = None
        self._cargar_modelo()
    
    def _cargar_modelo(self):
        """Carga el modelo perfeccionado con manejo de compatibilidad"""
        try:
            # Intentar cargar con joblib primero (m√°s robusto)
            try:
                with open(self.modelo_path, 'rb') as f:
                    data = joblib.load(f)
                    if isinstance(data, tuple) and len(data) >= 2:
                        self.modelo, self.scaler = data[0], data[1]
                        if len(data) == 3:
                            self.encoder = data[2]
                    else:
                        self.modelo = data
                print(f"‚úÖ Modelo cargado con joblib desde: {self.modelo_path}")
            except Exception as joblib_error:
                print(f"‚ö†Ô∏è Joblib fall√≥, intentando con pickle: {joblib_error}")
                # Fallback a pickle si joblib falla
                with open(self.modelo_path, 'rb') as f:
                    self.modelo, self.scaler = pickle.load(f)
                # El modelo tambi√©n incluye el encoder
                try:
                    with open(self.modelo_path, 'rb') as f:
                        data = pickle.load(f)
                        if len(data) == 3:
                            self.modelo, self.scaler, self.encoder = data
                except:
                    pass
                print(f"‚úÖ Modelo cargado con pickle desde: {self.modelo_path}")
        except Exception as e:
            print(f"‚ùå Error cargando modelo: {e}")
            # Si falla la carga del modelo, crear un modelo dummy para que la app funcione
            print("‚ö†Ô∏è Creando modelo dummy para continuar...")
            self.modelo = None
            self.scaler = None
            self.encoder = None
    
    def _clasificacion_basica(self, pixeles):
        """
        Clasificaci√≥n b√°sica basada en umbrales de color cuando el modelo no est√° disponible
        """
        # Convertir a HSV para mejor clasificaci√≥n
        hsv = cv2.cvtColor(pixeles.reshape(-1, 1, 3), cv2.COLOR_BGR2HSV).reshape(-1, 3)
        
        # Umbrales b√°sicos para clasificar suelo vs vegetaci√≥n
        # Suelo: valores bajos de saturaci√≥n y brillo
        suelo_mask = (hsv[:, 1] < 50) & (hsv[:, 2] < 120)
        
        # Vegetaci√≥n: valores altos de saturaci√≥n y verde
        vegetacion_mask = (hsv[:, 1] > 50) & (hsv[:, 0] > 30) & (hsv[:, 0] < 90)
        
        # Clasificar
        etiquetas = np.zeros(len(pixeles), dtype=int)
        etiquetas[suelo_mask] = 0  # Suelo
        etiquetas[vegetacion_mask] = 1  # Vegetaci√≥n
        
        return etiquetas
    
    def extraer_caracteristicas_optimizadas(self, pixeles):
        """
        Extrae caracter√≠sticas optimizadas basadas en an√°lisis de etiquetas
        """
        # RGB
        r, g, b = pixeles[:, 0], pixeles[:, 1], pixeles[:, 2]
        
        # HSV
        pixeles_uint8 = pixeles.astype(np.uint8)
        hsv = cv2.cvtColor(pixeles_uint8.reshape(-1, 1, 3), cv2.COLOR_BGR2HSV).reshape(-1, 3)
        h, s, v = hsv[:, 0], hsv[:, 1], hsv[:, 2]
        
        # Luminancia
        luminance = 0.299 * r + 0.587 * g + 0.114 * b
        
        # Saturaci√≥n
        saturation = s
        
        # NDVI aproximado
        ndvi = (g - r) / (g + r + 1e-8)
        
        # Textura (varianza local)
        texture = np.var(pixeles, axis=1)
        
        return np.column_stack([r, g, b, h, s, v, luminance, saturation, ndvi, texture])
    
    def procesar_imagen_completa(
        self,
        imagen_path: str,
        json_path: str,
        lugar: str,
        nombre_imagen: str,
        nombre_json: str
    ) -> Dict[str, Any]:
        """
        Procesa imagen completa con modelo perfeccionado
        """
        print(f"üì∏ Procesando: {nombre_imagen}")
        
        # Cargar imagen
        imagen = cv2.imread(imagen_path)
        if imagen is None:
            raise ValueError(f"No se pudo cargar la imagen: {imagen_path}")
        
        height, width = imagen.shape[:2]
        print(f"üìè Dimensiones: {width}x{height}")
        
        # Procesar imagen completa
        pixeles = imagen.reshape(-1, 3)
        caracteristicas = self.extraer_caracteristicas_optimizadas(pixeles)
        
        # Verificar si el modelo est√° disponible
        if self.modelo is None or self.scaler is None:
            print("‚ö†Ô∏è Modelo no disponible, usando clasificaci√≥n b√°sica...")
            # Clasificaci√≥n b√°sica basada en umbrales de color
            etiquetas_pred = self._clasificacion_basica(pixeles)
        else:
            # Escalar caracter√≠sticas
            caracteristicas_scaled = self.scaler.transform(caracteristicas)
            
            # Clasificar
            etiquetas_pred = self.modelo.predict(caracteristicas_scaled)
        
        # Calcular porcentajes
        porc_luz, porc_sombra, total_suelo = calcular_porcentaje_suelo(etiquetas_pred)
        
        print(f"üìä Resultados:")
        print(f"  Luz: {porc_luz:.1f}%")
        print(f"  Sombra: {porc_sombra:.1f}%")
        print(f"  Total suelo: {total_suelo}")
        
        # Generar imagen resultado
        ruta_imagen_resultado = self._generar_imagen_resultado_completa(
            imagen, etiquetas_pred, nombre_imagen
        )
        
        # Generar estad√≠sticas detalladas
        estadisticas_detalladas = {
            "total_pixeles": len(pixeles),
            "pixeles_luz": np.sum(etiquetas_pred == "LUZ"),
            "pixeles_sombra": np.sum(etiquetas_pred == "SOMBRA"),
            "pixeles_tronco": np.sum(etiquetas_pred == "TRONCO"),
            "pixeles_ignorado": np.sum(etiquetas_pred == "IGNORADO"),
            "dimensiones": {"ancho": width, "alto": height}
        }
        
        return {
            "lugar": lugar,
            "timestamp": datetime.utcnow(),
            "porcentaje_luz": float(porc_luz),
            "porcentaje_sombra": float(porc_sombra),
            "nombre_imagen": nombre_imagen,
            "nombre_json": nombre_json,
            "total_pixeles_suelo": int(total_suelo),
            "modelo_usado": "modelo_perfeccionado",
            "umbral_sombra": 0.4,
            "alerta_activada": "NO",
            "ruta_imagen_resultado": ruta_imagen_resultado,
            "estadisticas_detalladas": json.dumps(estadisticas_detalladas)
        }
    
    def _generar_imagen_resultado_completa(
        self,
        imagen_original: np.ndarray,
        etiquetas_pred_labels: np.ndarray,
        nombre_imagen: str
    ) -> str:
        """
        Genera imagen resultado completa con colores correctos
        """
        height, width = imagen_original.shape[:2]
        
        # Crear visualizaci√≥n
        visual_rgb = np.zeros((height, width, 3), dtype=np.uint8)
        
        # Mapear etiquetas a colores
        mask_luz = etiquetas_pred_labels == "LUZ"
        mask_sombra = etiquetas_pred_labels == "SOMBRA"
        mask_tronco = etiquetas_pred_labels == "TRONCO"
        mask_ignorado = etiquetas_pred_labels == "IGNORADO"
        
        # Reshape para imagen 2D
        mask_luz_2d = mask_luz.reshape((height, width))
        mask_sombra_2d = mask_sombra.reshape((height, width))
        mask_tronco_2d = mask_tronco.reshape((height, width))
        mask_ignorado_2d = mask_ignorado.reshape((height, width))
        
        # Aplicar colores (BGR format)
        visual_rgb[mask_luz_2d] = [0, 255, 255]      # Amarillo para luz (BGR)
        visual_rgb[mask_sombra_2d] = [50, 50, 50]    # Gris para sombra
        visual_rgb[mask_tronco_2d] = [0, 0, 255]     # Rojo para tronco (BGR)
        visual_rgb[mask_ignorado_2d] = [0, 0, 255]   # Rojo para ignorado (BGR)
        
        # Crear directorio de resultados si no existe
        os.makedirs("resultados", exist_ok=True)
        
        # Guardar imagen resultado
        nombre_archivo = f"resultado_{nombre_imagen}"
        ruta_completa = os.path.join("resultados", nombre_archivo)
        cv2.imwrite(ruta_completa, visual_rgb)
        
        print(f"üñºÔ∏è Imagen resultado guardada: {ruta_completa}")
        return ruta_completa
    
    def procesar_imagen_bytes(
        self,
        imagen_bytes: bytes,
        anotaciones_json: str,
        lugar: str,
        nombre_imagen: str = "imagen.jpg",
        nombre_json: str = "anotaciones.json"
    ) -> Dict[str, Any]:
        """
        Procesa imagen desde bytes (para API)
        """
        # Crear archivos temporales
        with tempfile.NamedTemporaryFile(suffix=".jpg", delete=False) as temp_img:
            temp_img.write(imagen_bytes)
            temp_img_path = temp_img.name
        
        with tempfile.NamedTemporaryFile(mode='w', suffix=".json", delete=False) as temp_json:
            temp_json.write(anotaciones_json)
            temp_json_path = temp_json.name
        
        try:
            # Procesar imagen
            resultado = self.procesar_imagen_completa(
                temp_img_path,
                temp_json_path,
                lugar,
                nombre_imagen,
                nombre_json
            )
            
            return resultado
            
        finally:
            # Limpiar archivos temporales
            os.unlink(temp_img_path)
            os.unlink(temp_json_path)
    
    def procesar_imagen_visual(self, imagen: np.ndarray) -> Tuple[float, float, np.ndarray]:
        """
        Procesa imagen para visualizaci√≥n - usa exactamente la misma l√≥gica que el c√≥digo original
        """
        try:
            height, width = imagen.shape[:2]
            print(f"üìè Dimensiones: {width}x{height}")
            
            # Aplicar el modelo si est√° disponible
            if self.modelo is not None and self.scaler is not None:
                # Procesar imagen completa como en el c√≥digo original
                pixeles = imagen.reshape(-1, 3)
                caracteristicas = self.extraer_caracteristicas_optimizadas(pixeles)
                
                # Escalar caracter√≠sticas
                caracteristicas_scaled = self.scaler.transform(caracteristicas)
                
                # Clasificar
                etiquetas_pred = self.modelo.predict(caracteristicas_scaled)
                
                # Decodificar etiquetas si hay encoder
                if self.encoder is not None:
                    etiquetas_pred = self.encoder.inverse_transform(etiquetas_pred)
                
                print(f"üîç Etiquetas predichas: {np.unique(etiquetas_pred, return_counts=True)}")
                
                # Calcular porcentajes usando la funci√≥n original
                from src.procesamiento.postprocesamiento import calcular_porcentaje_suelo
                porc_luz, porc_sombra, total_suelo = calcular_porcentaje_suelo(etiquetas_pred)
                
                # Crear m√°scaras como en el c√≥digo original
                mask_luz = etiquetas_pred == "LUZ"
                mask_sombra = etiquetas_pred == "SOMBRA"
                
                # Reshape para imagen 2D
                mask_luz_2d = mask_luz.reshape((height, width))
                mask_sombra_2d = mask_sombra.reshape((height, width))
                
                # Crear m√°scara combinada (luz = 255, sombra = 128, resto = 0)
                light_mask = np.zeros((height, width), dtype=np.uint8)
                light_mask[mask_luz_2d] = 255
                light_mask[mask_sombra_2d] = 128
                
                print(f"ü§ñ Modelo aplicado - Luz: {porc_luz:.1f}%, Sombra: {porc_sombra:.1f}%")
                
                return porc_luz, porc_sombra, light_mask
                
            else:
                # Fallback: usar umbralizaci√≥n simple
                gray = cv2.cvtColor(imagen, cv2.COLOR_BGR2GRAY)
                _, light_mask = cv2.threshold(gray, 128, 255, cv2.THRESH_BINARY)
                light_pixels = np.sum(light_mask == 255)
                total_pixels = gray.shape[0] * gray.shape[1]
                
                light_percentage = (light_pixels / total_pixels) * 100
                shadow_percentage = 100 - light_percentage
                print(f"üìä Fallback aplicado - Luz: {light_percentage:.1f}%, Sombra: {shadow_percentage:.1f}%")
                
                return light_percentage, shadow_percentage, light_mask
            
        except Exception as e:
            print(f"‚ùå Error en procesamiento visual: {e}")
            # Fallback: porcentajes aleatorios para testing
            return 50.0, 50.0, np.zeros((imagen.shape[0], imagen.shape[1]), dtype=np.uint8)
    
    def _extraer_caracteristicas_simples(self, gray: np.ndarray) -> np.ndarray:
        """
        Extrae caracter√≠sticas simples de la imagen en escala de grises
        """
        # Caracter√≠sticas b√°sicas
        mean_intensity = np.mean(gray)
        std_intensity = np.std(gray)
        
        # Histograma simplificado
        hist = cv2.calcHist([gray], [0], None, [8], [0, 256])
        hist_normalized = hist.flatten() / hist.sum()
        
        # Combinar caracter√≠sticas
        features = np.concatenate([
            [mean_intensity, std_intensity],
            hist_normalized
        ])
        
        return features